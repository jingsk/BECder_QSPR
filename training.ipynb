{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "if4LOLqdXyu9",
      "metadata": {
        "id": "if4LOLqdXyu9"
      },
      "source": [
        "You will have to restart twice during module install on colab. I need to install downgrade Torch version to ensure compatability. **Make sure to select T4 GPU under Resource.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b_sh1MFCBItF",
      "metadata": {
        "id": "b_sh1MFCBItF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "if torch.__version__ != '2.5.1+cu121':\n",
        "    !pip install ipython==8.1.0\n",
        "    !pip uninstall torch torch-scatter torch-sparse torch-geometric torch-cluster  --y\n",
        "    !pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu121\n",
        "try:\n",
        "    from becderqspr.data import train_valid_test_split\n",
        "except ModuleNotFoundError:\n",
        "    !pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "    !pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "    !pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "    !pip install e3nn\n",
        "    !pip install torch-geometric -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "    !git clone https://github.com/jingsk/BECder_QSPR.git\n",
        "    %cd /content/BECder_QSPR\n",
        "    !pip install .\n",
        "try:\n",
        "    import cmcrameri.cm as cm\n",
        "except ModuleNotFoundError:\n",
        "    !pip install cmcrameri\n",
        "\n",
        "try:\n",
        "    from ase import Atom, Atoms\n",
        "except ModuleNotFoundError:\n",
        "    !pip install ase\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f8ced87-a66e-4958-872f-0565a7edd12f",
      "metadata": {
        "id": "2f8ced87-a66e-4958-872f-0565a7edd12f"
      },
      "outputs": [],
      "source": [
        "# model\n",
        "import torch\n",
        "#import torch.nn as nn\n",
        "#import torch.nn.functional as F\n",
        "import torch_geometric as tg\n",
        "#import torch_scatter\n",
        "import e3nn\n",
        "from e3nn import o3\n",
        "from e3nn.io import CartesianTensor\n",
        "from e3nn.o3 import ReducedTensorProducts\n",
        "from typing import Dict, Union\n",
        "from becderqspr.data import train_valid_test_split\n",
        "#from utils.e3nn import Network\n",
        "from becderqspr.model import E3NN\n",
        "\n",
        "import cmcrameri.cm as cm\n",
        "\n",
        "# crystal structure data\n",
        "from ase import Atom, Atoms\n",
        "from ase.neighborlist import neighbor_list\n",
        "from ase.visualize.plot import plot_atoms\n",
        "\n",
        "# data pre-processing and visualization\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# utilities\n",
        "from tqdm import tqdm\n",
        "from becderqspr.data import load_db\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "bar_format = '{l_bar}{bar:10}{r_bar}{bar:-10b}'\n",
        "tqdm.pandas(bar_format=bar_format)\n",
        "default_dtype = torch.float64\n",
        "torch.set_default_dtype(default_dtype)\n",
        "device = \"cuda\"\n",
        "\n",
        "tijk = CartesianTensor(\"ijk=ikj\")\n",
        "rtp = ReducedTensorProducts(\"ijk=ikj\", i='1o', j='1o')\n",
        "\n",
        "r_max = 3.5 # cutoff radius"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0mg_8hgAa7eo",
      "metadata": {
        "id": "0mg_8hgAa7eo"
      },
      "source": [
        "Each ASE Atoms object and its BECder data (per atom rank-3 tensor) are stored as entries in ASE database. We load this database into Pandas DataFrame here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa0044d7-d355-4a98-9b07-50b4ebcee0e4",
      "metadata": {
        "id": "aa0044d7-d355-4a98-9b07-50b4ebcee0e4"
      },
      "outputs": [],
      "source": [
        "# load data\n",
        "df, species = load_db('/content/BECder_QSPR/data/bec_der.db', selection=None)\n",
        "species = [Atom(k).number for k in species]\n",
        "Z_max = max([Atom(k).number for k in species])\n",
        "\n",
        "# one-hot encoding atom type and mass\n",
        "type_encoding = {}\n",
        "specie_am = []\n",
        "for Z in tqdm(range(1, Z_max+1), bar_format=bar_format):\n",
        "    specie = Atom(Z)\n",
        "    type_encoding[specie.symbol] = Z - 1\n",
        "    specie_am.append(specie.mass)\n",
        "\n",
        "type_onehot = torch.eye(len(type_encoding))\n",
        "am_onehot = torch.diag(torch.tensor(specie_am))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cnN5-Zmbb8B",
      "metadata": {
        "id": "9cnN5-Zmbb8B"
      },
      "source": [
        "Create chemical graph from Pandas DF. It is crucial that the each vertex points to itself for message passing (currently done with ASE's neighbor_list with self_interaction=True)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8cd9302-8a30-417f-aecf-af8204a88aeb",
      "metadata": {
        "id": "b8cd9302-8a30-417f-aecf-af8204a88aeb"
      },
      "outputs": [],
      "source": [
        "# create chemical graph\n",
        "def build_data(entry, type_encoding, type_onehot, r_max=3.5):\n",
        "\n",
        "    symbols = list(entry.structure.symbols).copy()\n",
        "    positions = torch.from_numpy(entry.structure.positions.copy())\n",
        "    lattice = torch.from_numpy(entry.structure.cell.array.copy()).unsqueeze(0)\n",
        "\n",
        "    # edge_src and edge_dst are the indices of the central and neighboring atom, respectively\n",
        "    # edge_shift indicates whether the neighbors are in different images or copies of the unit cell\n",
        "    edge_src, edge_dst, edge_shift = neighbor_list(\"ijS\", a=entry.structure, cutoff=r_max, self_interaction=True)\n",
        "\n",
        "    # compute the relative distances and unit cell shifts from periodic boundaries\n",
        "    edge_batch = positions.new_zeros(positions.shape[0], dtype=torch.long)[torch.from_numpy(edge_src)]\n",
        "    edge_vec = (positions[torch.from_numpy(edge_dst)]\n",
        "                - positions[torch.from_numpy(edge_src)]\n",
        "                + torch.einsum('ni,nij->nj', torch.tensor(edge_shift, dtype=default_dtype), lattice[edge_batch]))\n",
        "\n",
        "    # compute edge lengths (rounded only for plotting purposes)\n",
        "    edge_len = np.around(edge_vec.norm(dim=1).numpy(), decimals=2)\n",
        "\n",
        "    data = tg.data.Data(\n",
        "        pos=positions, lattice=lattice, symbol=symbols,\n",
        "        x_in=am_onehot[[type_encoding[specie] for specie in symbols]],   # atomic mass (node feature)\n",
        "        z_in=type_onehot[[type_encoding[specie] for specie in symbols]], # atom type (node attribute)\n",
        "        edge_index=torch.stack([torch.LongTensor(edge_src), torch.LongTensor(edge_dst)], dim=0),\n",
        "        edge_shift=torch.tensor(edge_shift, dtype=default_dtype),\n",
        "        edge_vec=edge_vec, edge_len=edge_len,\n",
        "        #y=CartesianTensor(\"ij=ji\").from_cartesian(torch.from_numpy(entry.diel), rtp=ReducedTensorProducts('ij=ji', i='1o')).unsqueeze(0),\n",
        "        b=tijk.from_cartesian(torch.from_numpy(np.array(entry.becder)), rtp=rtp).unsqueeze(0),\n",
        "    )\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "df['data'] = df.progress_apply(lambda x: build_data(x, type_encoding, type_onehot, r_max), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0007ae6-097d-47b4-a741-84a426554682",
      "metadata": {
        "id": "f0007ae6-097d-47b4-a741-84a426554682"
      },
      "outputs": [],
      "source": [
        "# Train/valid/test split\n",
        "valid_size = 0.1\n",
        "test_size = 0.1\n",
        "idx_train, idx_valid, idx_test = train_valid_test_split(df.data, valid_size=valid_size, test_size=test_size)\n",
        "# Format dataloaders\n",
        "batch_size = 4\n",
        "dataloader_train = tg.loader.DataLoader(df.iloc[idx_train]['data'].tolist(), batch_size=batch_size, shuffle=True)\n",
        "dataloader_valid = tg.loader.DataLoader(df.iloc[idx_valid]['data'].tolist(), batch_size=batch_size)\n",
        "dataloader_test = tg.loader.DataLoader(df.iloc[idx_test]['data'].tolist(), batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caac8d22-0f76-4530-a007-9ea8852b2a85",
      "metadata": {
        "id": "caac8d22-0f76-4530-a007-9ea8852b2a85"
      },
      "outputs": [],
      "source": [
        "#Z_max = 4\n",
        "args_enn = {'in_dim': Z_max,\n",
        "            'emb_dim': 4,\n",
        "            'num_layers': 2,\n",
        "            'max_radius': r_max,\n",
        "            'num_neighbors': 10,\n",
        "           }\n",
        "\n",
        "enn = E3NN(**args_enn).to(device)\n",
        "opt = torch.optim.Adam(enn.parameters(), lr=1e-3)\n",
        "scheduler = None #torch.optim.lr_scheduler.ExponentialLR(opt, gamma=0.99)\n",
        "\n",
        "!mkdir -p models\n",
        "model_path = 'models/' + enn.model_name + '.torch'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92a202cc-9895-4282-845d-71ad05af8729",
      "metadata": {
        "collapsed": true,
        "id": "92a202cc-9895-4282-845d-71ad05af8729"
      },
      "outputs": [],
      "source": [
        "resume = False\n",
        "max_iter = 40\n",
        "\n",
        "if resume:\n",
        "    saved = torch.load(model_path, map_location=device)\n",
        "    enn.load_state_dict(saved['state'])\n",
        "    opt.load_state_dict(saved['optimizer'])\n",
        "    try:\n",
        "        scheduler.load_state_dict(saved['scheduler'])\n",
        "    except:\n",
        "        scheduler = None\n",
        "    history = saved['history']\n",
        "    s0 = history[-1]['step'] + 1\n",
        "    print(f'loading from {model_path}')\n",
        "    print(f'Starting from step {s0:d}/{max_iter:d}')\n",
        "\n",
        "else:\n",
        "    history = []\n",
        "    s0 = 0\n",
        "\n",
        "# fit E3NN\n",
        "for results in enn.fit(opt, dataloader_train, dataloader_valid, history, s0, max_iter=max(0,max_iter-s0), device=device,\n",
        "                       scheduler=scheduler):\n",
        "    with open(model_path, 'wb') as f:\n",
        "        torch.save(results, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3964847-4630-40bb-8257-dedb948d32fb",
      "metadata": {
        "id": "f3964847-4630-40bb-8257-dedb948d32fb"
      },
      "outputs": [],
      "source": [
        "saved = torch.load(model_path, map_location=device)\n",
        "history = saved['history']\n",
        "\n",
        "steps = [d['step'] + 1 for d in history]\n",
        "loss_train = [d['train']['loss'] for d in history]\n",
        "loss_valid = [d['valid']['loss'] for d in history]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(3.5,3))\n",
        "ax.plot(steps, loss_train, label='Train', color='red')\n",
        "ax.plot(steps, loss_valid, label='Valid.', color='blue')\n",
        "ax.set_xlabel('Iterations')\n",
        "ax.set_ylabel('Loss')\n",
        "ax.legend(frameon=False)\n",
        "ax.set_yscale('log')\n",
        "!mkdir -p images\n",
        "fig.savefig('images/loss.png', dpi=300, bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XSGaRkmjb9zs",
      "metadata": {
        "id": "XSGaRkmjb9zs"
      },
      "source": [
        "Now let's see how the model performs. On the left (right) the color map shows the value of the real (predicted) BECder tensors along x,y,z cartesian positional index for selected Mo or S atoms. The red text on the left shows the value of the BECder tensor while on the right shows the prediction error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74aec8a2-da98-410d-a885-e5b995404315",
      "metadata": {
        "id": "74aec8a2-da98-410d-a885-e5b995404315"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def cart_idx_to_str(i):\n",
        "    if i==0: return 'x' \n",
        "    if i==1: return 'y' \n",
        "    if i==2: return 'z' \n",
        "    else: return None\n",
        "\n",
        "@torch.no_grad()\n",
        "def calculate_becder(entry, enn):\n",
        "    x = entry.data\n",
        "    x.pos.requires_grad = True\n",
        "\n",
        "    b_pred = enn(x.to(device))\n",
        "    #bec_pred = CartesianTensor(\"ij=ij\").to_cartesian(bec_pred.detach().cpu())\n",
        "    b_pred = tijk.to_cartesian(b_pred.detach().cpu(), rtp)\n",
        "    b_pred = b_pred.reshape(-1,3,3,3)\n",
        "    return b_pred\n",
        "\n",
        "def print_text(ax, mat):\n",
        "    for i in range(3):\n",
        "        for j in range(3):\n",
        "            text = ax.text(i,j, f\"{mat[i, j]:.3f}\",\n",
        "                           color='tab:red', size=10, ha='center', va='center')\n",
        "\n",
        "def visualize_output(entry: pd.Series, enn: E3NN, device: str):\n",
        "    import torch_geometric as tg\n",
        "    from e3nn.io import CartesianTensor\n",
        "    import matplotlib.pyplot as plt\n",
        "    import matplotlib as mpl\n",
        "\n",
        "    idx_to_plt = [0, 1, 2] \n",
        "    x = tg.data.Batch.from_data_list([entry.data])\n",
        "    #x.pos.requires_grad = True\n",
        "    tensor_pred = calculate_becder(entry, enn)\n",
        "    #b_pred = b_pred.reshape(-1,3,3)\n",
        "    tensor_real = entry.becder.reshape(-1,3,3,3)\n",
        "    # b_real = b_real.numpy()\n",
        "    # b_pred = b_pred.numpy()\n",
        "\n",
        "    for atoms_idx in idx_to_plt:\n",
        "        b_real = tensor_real[atoms_idx]\n",
        "        b_pred = tensor_pred[atoms_idx]\n",
        "        fig, axs = plt.subplots(3,3, \n",
        "                              figsize=(4.5,3* 2), \n",
        "                              gridspec_kw={'width_ratios': [1,1,0.07]}\n",
        "                              )\n",
        "        plt.subplots_adjust(wspace=0.1)\n",
        "        \n",
        "        vmax = np.max(np.abs(ylims))\n",
        "        norm = plt.Normalize(vmin=-vmax, vmax=vmax)\n",
        "        \n",
        "        sm = mpl.cm.ScalarMappable(cmap=mpl.colormaps['RdBu'], norm=norm)\n",
        "        #sm = mpl.cm.ScalarMappable(cmap=cm.twilight_shifted, norm=norm)\n",
        "        for k in range(3):\n",
        "            axs[k,0].imshow(b_real[k], cmap=sm.cmap, norm=sm.norm)\n",
        "            axs[k,1].imshow(b_pred[k], cmap=sm.cmap, norm=sm.norm)\n",
        "            axs[k,0].set_xticks([]); axs[k,1].set_xticks([])\n",
        "            axs[k,0].set_yticks([]); axs[k,1].set_yticks([])\n",
        "            if k>0:\n",
        "                axs[k,2].set_visible(False)\n",
        "            #axs[k,1].set_visible(False)\n",
        "            print_text(axs[k,0], b_real[k])\n",
        "            print_text(axs[k,1], b_pred[k]-b_real[k])\n",
        "            axs[k,0].text(-0.025,1.025, cart_idx_to_str(k),color='black', size=10,transform=axs[k,0].transAxes)\n",
        "            \n",
        "        \n",
        "        #plot format\n",
        "        axs[0,0].set_title('True (num: value)')\n",
        "        axs[0,1].set_title('Pred. (num: error)')\n",
        "        #axs[:,2].set_visible(True)\n",
        "        cbar = plt.colorbar(sm, cax=axs[0,2],extend='both')\n",
        "        # cbar.set_ylim(ylims)\n",
        "        plt.tight_layout()\n",
        "        #fig.savefig(file_name, dpi=600)\n",
        "        fig.savefig(f'./images/example_becder_test_iloc0_atoms{atoms_idx}.png', bbox_inches='tight', transparent=False)\n",
        "    \n",
        "\n",
        "\n",
        "enn.load_state_dict(saved['state'])\n",
        "entry = df.iloc[idx_test].iloc[0]\n",
        "ylims = [-3,3]\n",
        "visualize_output(entry, enn, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83a16234-61f1-4b03-a939-4037a27afe23",
      "metadata": {
        "id": "83a16234-61f1-4b03-a939-4037a27afe23"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
